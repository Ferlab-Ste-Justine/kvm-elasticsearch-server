# About

This terraform module provisions an elasticsearch 7 cluster for libvirt/kvm.

# Limitations

## Security

While tls is enabled, access-control is currently disabled.

For this reason, the cluster should be running on a private network.

We tried integrating pki authentication, but Elastic is restricting that feature to those who have a Gold or better license, which, to put it diplomatically, is an interesting choice to say the least.

Potential solutions we are contemplating are:
- Using password authentication instead
- Using an additional networking security layer (ex: Haproxy or even a service mesh)
- Switching to Opensearch

## Initial Masters

Elasticsearch expect a list of initial masters to be present in the configuration for, and only for, the cluster initialization.

The module resolve this issue for the initial nodes by removing that part of the configuration after the cluster is initialized (in case the nodes reboot at some point).

However, for new nodes you add to an existing cluster, you will need to be mindful about not setting that field. 

## Prerequisites

The module has been developped with an recent Ubuntu image. Your mileage may vary with other distributions.

Furthermore, the module assumes that you have a dynamically configurable dns service that will be modified as part of the terraform execution for master discovery.

## Node Roles Topology Assumption

The module assumes that you will be working with dedicated masters nodes and dedicated worker nodes and supports that use-case.

## Dangling Backup Parameters

The module currently takes the following parameters for incremental backups in s3 stores:
- **s3_endpoint**
- **s3_protocol**
- **s3_access_key**
- **s3_secret_key**

Those parameters should not be used as incremental backup is not yet functional.

It may or may not work fine in **Aws s3**, but after days of trying to make it work with **Ceph**, we decided to postpone that feature of the module for now. We haven't tried integrating it with **Minio** yet.

# Usage

## Input Variables

- **name**: Name to give to the vm. Will be the hostname as well.
- **cluster_name**: Name of the elasticsearch cluster the server will join.
- **vcpus**: Number of vcpus to assign to the vm. Defaults to 2.
- **memory**: Amount of memory in MiB to assign to the vm. Defaults to 8192.
- **volume_id**: Id of the image volume to attach to the vm. A recent version of ubuntu is recommended as this is what this module has been validated against.
- **network_id**: Id (ie, uuid) of the libvirt network to connect the vm to if you wish to connect the vm to a libvirt network.
- **ip**: Ip of the vm if you opt to connect it to a libvirt network. Note that this isn't an optional parameter. Dhcp cannot be used.
- **mac**: Mac address of the vm if you opt to connect it to a libvirt network. If none is passed, a random one will be generated.
- **macvtap_interfaces**: List of macvtap interfaces to connect the vm to if you opt for macvtap interfaces instead of a libvirt network. Each entry in the list is a map with the following keys:
  - **interface**: Host network interface that you plan to connect your macvtap interface with.
  - **prefix_length**: Length of the network prefix for the network the interface will be connected to. For a **192.168.1.0/24** for example, this would be 24.
  - **ip**: Ip associated with the macvtap interface. 
  - **mac**: Mac address associated with the macvtap interface.
  - **gateway**: Ip of the network's gateway for the network the interface will be connected to.
  - **dns_servers**: Dns servers for the network the interface will be connected to. If there aren't dns servers setup for the network your vm will connect to, the ip of external dns servers accessible accessible from the network will work as well.
- **cloud_init_volume_pool**: Name of the volume pool that will contain the cloud-init volume of the vm.
- **cloud_init_volume_name**: Name of the cloud-init volume that will be generated by the module for your vm. If left empty, it will default to ``<vm name>-cloud-init.iso``.
- **ssh_admin_user**: Username of the default sudo user in the image. Defaults to **ubuntu**.
- **admin_user_password**: Optional password for the default sudo user of the image. Note that this will not enable ssh password connections, but it will allow you to log into the vm from the host using the **virsh console** command.
- **ssh_admin_public_key**: Public part of the ssh key that will be used to login as the admin on the vm
- **domain**: Domain of the cluster, also used for master discovery. Should have a **masters** subdomain that resolves to the ip of the masters and a **workers** subdomain that resolves to the ip of the workers.
- **initial_masters**: List of host names for the initial masters to bootstrap the cluster when it is created with its initial nodes. Should be empty for additional servers that will be added to the cluster later on.
- **nameserver_ips**: Ips of nameservers that are to be used for master discovery. This list can be left blank if the network's dns servers already fulfill that role.
- **is_master**: Whether the server is a master. Otherwise, it will be a worker.
- **tls_enabled**: Whether the elasticsearch server should communicate over https or regular http.
- **chrony**: Optional chrony configuration for when you need a more fine-grained ntp setup on your vm. It is an object with the following fields:
  - **enabled**: If set the false (the default), chrony will not be installed and the vm ntp settings will be left to default.
  - **servers**: List of ntp servers to sync from with each entry containing two properties, **url** and **options** (see: https://chrony.tuxfamily.org/doc/4.2/chrony.conf.html#server)
  - **pools**: A list of ntp server pools to sync from with each entry containing two properties, **url** and **options** (see: https://chrony.tuxfamily.org/doc/4.2/chrony.conf.html#pool)
  - **makestep**: An object containing remedial instructions if the clock of the vm is significantly out of sync at startup. It is an object containing two properties, **threshold** and **limit** (see: https://chrony.tuxfamily.org/doc/4.2/chrony.conf.html#makestep)

The following variables are used to serve traffic over tls, if enabled:
- **ca**: Certificate authority used to sign the certificate of the server. It is an object with the following fields:
  - **key**: Private key that was used to sign the ca certificate
  - **key_algorithm**: Algorithm of the private key that was used to sign the ca certificate
  - **certificate**: The ca's certificate 
- **server_certificate**: Parameters for the server's certificate. It is an object with the following fields:
  - **organization**: The es server certificate's organization. Defaults to **Ferlab**
  - **certificate_validity_period**: The validity period of the certificate for the es server. Defaults to 100 years.
  - **certificate_early_renewal_period**: Period before the certificate's expiry when Terraform will try to auto-renew the certificate for the es server. Defaults to 1 year. 
  - **key_length**: Key lenght of the certificate's private key. Defaults to 4096.

## Example

Here's an example of how this module would be used:

```
module "es_domain" {
  source = "git::https://github.com/Ferlab-Ste-Justine/etcd-zonefile.git"
  domain = "es.local"
  key_prefix = "/coredns/"
  dns_server_name = "ns.local."
  a_records = concat(
    [for addr in netaddr_address_ipv4.es_master: {
      prefix = "masters"
      ip = addr.address
    }],
    [for addr in netaddr_address_ipv4.es_worker: {
      prefix = "workers"
      ip = addr.address
    }]
  )
}

resource "netaddr_address_ipv4" "es_master" {
    count = 3
    range_id = data.netaddr_range_ipv4.vlan.id
    name = "es-master-${count.index + 1}"
}

resource "netaddr_address_mac" "es_master" {
    count    = 3
    range_id = data.netaddr_range_mac.vlan.id
    name     = "es-master-${count.index + 1}"
}

resource "libvirt_volume" "master_1" {
  provider         = libvirt.machine1
  name             = "es-master-1"
  pool             = "elasticsearch"
  // 20 GiB
  size             = 20 * 1024 * 1024 * 1024
  base_volume_pool = "os"
  base_volume_name = "ubuntu"
  format = "qcow2"

  lifecycle {
    prevent_destroy = true
  }
}

resource "libvirt_volume" "master_2" {
  provider         = libvirt.machine2
  name             = "es-master-2"
  pool             = "elasticsearch"
  // 20 GiB
  size             = 20 * 1024 * 1024 * 1024
  base_volume_pool = "os"
  base_volume_name = "ubuntu"
  format = "qcow2"

  lifecycle {
    prevent_destroy = true
  }
}

resource "libvirt_volume" "master_3" {
  provider         = libvirt.machine3
  name             = "es-master-3"
  pool             = "elasticsearch"
  // 20 GiB
  size             = 20 * 1024 * 1024 * 1024
  base_volume_pool = "os"
  base_volume_name = "ubuntu"
  format = "qcow2"

  lifecycle {
    prevent_destroy = true
  }
}

module "master_1" {
  source = "git::https://github.com/Ferlab-Ste-Justine/kvm-elasticsearch-server.git"
  providers = {
    libvirt = libvirt.machine1
  }
  name = "es-master-1"
  cluster_name = "es"
  vcpus = 2
  memory = 8192
  volume_id = libvirt_volume.master_1.id
  macvtap_interfaces = [
    {
      interface = local.networks.networks.vlan.interface
      prefix_length = local.networks.networks.vlan.prefix
      gateway = local.networks.networks.vlan.gateway
      dns_servers = local.networks.networks.vlan.dns
      ip = netaddr_address_ipv4.es_master.0.address
      mac = netaddr_address_mac.es_master.0.address
    }
  ]
  cloud_init_volume_pool = "elasticsearch"
  ssh_admin_public_key = local.server_ssh_public_key
  admin_user_password = local.console_password
  domain = "es.local"
  nameserver_ips = [for coredns in data.netaddr_address_ipv4.coredns: coredns.address]
  is_master = true
  initial_masters = [for master in netaddr_address_ipv4.es_master: master.address]
  ca = local.es_ca
}

module "master_2" {
  source = "git::https://github.com/Ferlab-Ste-Justine/kvm-elasticsearch-server.git"
  providers = {
    libvirt = libvirt.machine2
  }
  name = "es-master-2"
  cluster_name = "es"
  vcpus = 2
  memory = 8192
  volume_id = libvirt_volume.master_2.id
  macvtap_interfaces = [
    {
      interface = local.networks.networks.vlan.interface
      prefix_length = local.networks.networks.vlan.prefix
      gateway = local.networks.networks.vlan.gateway
      dns_servers = local.networks.networks.vlan.dns
      ip = netaddr_address_ipv4.es_master.1.address
      mac = netaddr_address_mac.es_master.1.address
    }
  ]
  cloud_init_volume_pool = "elasticsearch"
  ssh_admin_public_key = local.server_ssh_public_key
  admin_user_password = local.console_password
  domain = "es.local"
  nameserver_ips = [for coredns in data.netaddr_address_ipv4.coredns: coredns.address]
  is_master = true
  initial_masters = [for master in netaddr_address_ipv4.es_master: master.address]
  ca = local.es_ca
}

module "master_3" {
  source = "git::https://github.com/Ferlab-Ste-Justine/kvm-elasticsearch-server.git"
  providers = {
    libvirt = libvirt.machine3
  }
  name = "es-master-3"
  cluster_name = "es"
  vcpus = 2
  memory = 8192
  volume_id = libvirt_volume.master_3.id
  macvtap_interfaces = [
    {
      interface = local.networks.networks.vlan.interface
      prefix_length = local.networks.networks.vlan.prefix
      gateway = local.networks.networks.vlan.gateway
      dns_servers = local.networks.networks.vlan.dns
      ip = netaddr_address_ipv4.es_master.2.address
      mac = netaddr_address_mac.es_master.2.address
    }
  ]
  cloud_init_volume_pool = "elasticsearch"
  ssh_admin_public_key = local.server_ssh_public_key
  admin_user_password = local.console_password
  domain = "es.local"
  nameserver_ips = [for coredns in data.netaddr_address_ipv4.coredns: coredns.address]
  is_master = true
  initial_masters = [for master in netaddr_address_ipv4.es_master: master.address]
  ca = local.es_ca
}

resource "netaddr_address_ipv4" "es_worker" {
    count    = 3
    range_id = data.netaddr_range_ipv4.vlan.id
    name     = "es-worker-${count.index + 1}"
}

resource "netaddr_address_mac" "es_worker" {
    count    = 3
    range_id = data.netaddr_range_ipv4.vlan.id
    name     = "es-worker-${count.index + 1}"
}

resource "libvirt_volume" "worker_1" {
  provider         = libvirt.machine1
  name             = "es-worker-1"
  pool             = "elasticsearch"
  // 20 GiB
  size             = 20 * 1024 * 1024 * 1024
  base_volume_pool = "os"
  base_volume_name = "ubuntu"
  format = "qcow2"

  lifecycle {
    prevent_destroy = true
  }
}

resource "libvirt_volume" "worker_2" {
  provider         = libvirt.machine2
  name             = "es-worker-2"
  pool             = "elasticsearch"
  // 20 GiB
  size             = 20 * 1024 * 1024 * 1024
  base_volume_pool = "os"
  base_volume_name = "ubuntu"
  format = "qcow2"

  lifecycle {
    prevent_destroy = true
  }
}

resource "libvirt_volume" "worker_3" {
  provider         = libvirt.machine3
  name             = "es-worker-3"
  pool             = "elasticsearch"
  // 20 GiB
  size             = 20 * 1024 * 1024 * 1024
  base_volume_pool = "os"
  base_volume_name = "ubuntu"
  format = "qcow2"

  lifecycle {
    prevent_destroy = true
  }
}

module "worker_1" {
  source = "git::https://github.com/Ferlab-Ste-Justine/kvm-elasticsearch-server.git"
  providers = {
    libvirt = libvirt.machine1
  }
  name = "es-worker-1"
  cluster_name = "es"
  vcpus = 2
  memory = 8192
  volume_id = libvirt_volume.worker_1.id
  macvtap_interfaces = [
    {
      interface = local.networks.networks.vlan.interface
      prefix_length = local.networks.networks.vlan.prefix
      gateway = local.networks.networks.vlan.gateway
      dns_servers = local.networks.networks.vlan.dns
      ip = netaddr_address_ipv4.es_worker.0.address
      mac = netaddr_address_mac.es_worker.0.address
    }
  ]
  cloud_init_volume_pool = "elasticsearch"
  ssh_admin_public_key = local.server_ssh_public_key
  admin_user_password = local.console_password
  domain = "es.local"
  nameserver_ips = [for coredns in data.netaddr_address_ipv4.coredns: coredns.address]
  is_master = false
  initial_masters = [for master in netaddr_address_ipv4.es_master: master.address]
  ca = local.es_ca
}

module "worker_2" {
  source = "git::https://github.com/Ferlab-Ste-Justine/kvm-elasticsearch-server.git"
  providers = {
    libvirt = libvirt.machine2
  }
  name = "es-worker-2"
  cluster_name = "es"
  vcpus = 2
  memory = 8192
  volume_id = libvirt_volume.worker_2.id
  macvtap_interfaces = [
    {
      interface = local.networks.networks.vlan.interface
      prefix_length = local.networks.networks.vlan.prefix
      gateway = local.networks.networks.vlan.gateway
      dns_servers = local.networks.networks.vlan.dns
      ip = netaddr_address_ipv4.es_worker.1.address
      mac = netaddr_address_mac.es_worker.1.address
    }
  ]
  cloud_init_volume_pool = "elasticsearch"
  ssh_admin_public_key = local.server_ssh_public_key
  admin_user_password = local.console_password
  domain = "es.local"
  nameserver_ips = [for coredns in data.netaddr_address_ipv4.coredns: coredns.address]
  is_master = false
  initial_masters = [for master in netaddr_address_ipv4.es_master: master.address]
  ca = local.es_ca
}

module "worker_3" {
  source = "git::https://github.com/Ferlab-Ste-Justine/kvm-elasticsearch-server.git"
  providers = {
    libvirt = libvirt.machine3
  }
  name = "es-worker-3"
  cluster_name = "es"
  vcpus = 2
  memory = 8192
  volume_id = libvirt_volume.worker_3.id
  macvtap_interfaces = [
    {
      interface = local.networks.networks.vlan.interface
      prefix_length = local.networks.networks.vlan.prefix
      gateway = local.networks.networks.vlan.gateway
      dns_servers = local.networks.networks.vlan.dns
      ip = netaddr_address_ipv4.es_worker.2.address
      mac = netaddr_address_mac.es_worker.2.address
    }
  ]
  cloud_init_volume_pool = "elasticsearch"
  ssh_admin_public_key = local.server_ssh_public_key
  admin_user_password = local.console_password
  domain = "es.local"
  nameserver_ips = [for coredns in data.netaddr_address_ipv4.coredns: coredns.address]
  is_master = false
  initial_masters = [for master in netaddr_address_ipv4.es_master: master.address]
  ca = local.es_ca
}
```